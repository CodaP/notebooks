{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "figsize(15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of our three scenarios we created a randomized set of queries on a list of 5 objects, normalized to 1. The distribution of each was proportioned such that it modeled the characteristics of of each senario as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Big Event\" Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"big event\" is a scenario where some large news event ocurres skewing the distribution of queries suddenly and persiting for some time. We did this by first having an unbiased random distribution of queries for some time then skewing them in favor of one particulat query, as shown by the distribution graph below. This kind of scenario is useful for a self organizing list because the \"big event\" can be pulled to the frount of the list making it more eficient to find results on when it is a common search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data1 = pd.DataFrame(np.abs(np.random.randn(50,5)))\n",
    "sample_data1 = sample_data1.apply(lambda x: x/x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data2 = pd.DataFrame(np.abs(np.random.randn(50,5)),index=range(50,100))\n",
    "sample_data2.ix[:,0] += 25\n",
    "sample_data2 = sample_data2.apply(lambda x: x/x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_event_dist = pd.concat([sample_data1,sample_data2]).cumsum(axis=1)\n",
    "big_event_queries = np.random.ranf(100)\n",
    "big_event_dist['rand'] = big_event_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries for \"Big Event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_event_queries = 4-big_event_dist.apply(lambda x: (x.iloc[:4] > x.rand).sum(),axis=1)\n",
    "big_event_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of \"Big Event\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([sample_data1,sample_data2]).plot(kind='area')\n",
    "title('Big Event')\n",
    "_ = legend(framealpha=1,loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Viral Video\" Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viral videos do not exist one day and then suddenly rise to poularity before people lose intrest and the video fades into obscurity. The simulation is fairly similar to the big event case only that the querrie does not exist before its rise and relativly short period of time it fades into the backround as average as any other query. This give a simulation of a search falling out of high priority and can be useful to show how these algorithms sort themselves out on a downtern in searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data3 = pd.DataFrame(np.abs(np.random.randn(50,5)),index=range(50,100))\n",
    "sine = np.sin((sample_data3.index.values+0.0)/sample_data3.index.values.size*2*np.pi)\n",
    "sine[sine < 0] = 0\n",
    "sample_data3.ix[:,0] += sine*10\n",
    "sample_data3.ix[sample_data3.ix[:,0] < 0,0] = 0\n",
    "sample_data3 = sample_data3.apply(lambda x: x/x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data4 = pd.DataFrame(np.abs(np.random.randn(50,5)))\n",
    "sample_data4.ix[:,0] = 0\n",
    "sample_data4 = sample_data4.apply(lambda x: x/x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viral_dist = pd.concat([sample_data4,sample_data3]).cumsum(axis=1)\n",
    "viral_queries = np.random.ranf(100)\n",
    "viral_dist['rand'] = viral_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries for \"Viral Video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viral_queries = 4-viral_dist.apply(lambda x: (x.iloc[:4] > x.rand).sum(),axis=1)\n",
    "viral_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of \"Viral Video\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([sample_data4,sample_data3]).plot(kind='area')\n",
    "_ = legend(framealpha=1,loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lopsided but constant distribtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this last scenario we wanted to see how each algorithm would work in a very steady state, with each query being uniformly distributed except for one which it is biased towards. No real world case would be this steady but we felt it was important to have a base case for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Lopsided but constant distribution\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constant_dist = pd.DataFrame(np.ones((100,5)),index=range(100))\n",
    "constant_dist.ix[:] = 1./3/4\n",
    "constant_dist.ix[:,0] = 2./3\n",
    "constant_dist['rand'] = np.random.ranf(100)\n",
    "constant_queries = 4-constant_dist.cumsum(axis=1).apply(lambda x: (x.iloc[:4] > x.rand-1).sum(),axis=1)\n",
    "constant_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Lopsided but constant distribution\" distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constant_dist.iloc[:,:5].plot(kind='area')\n",
    "_ = legend(loc='best', framealpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Linked list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        \n",
    "    def push(self,item):\n",
    "        self.head = [item,self.head]\n",
    "        \n",
    "    def pop(self):\n",
    "        popped,self.head = self.head\n",
    "        return popped\n",
    "    \n",
    "    def insert(self,item,index):\n",
    "        if index == 0:\n",
    "            self.head = (item,self.head)\n",
    "        else:\n",
    "            parent_node = self.get(index-1)\n",
    "            parent_node[1] = [item,parent_node[1]]\n",
    "            \n",
    "                \n",
    "    def get(self,index):\n",
    "        node = self.head\n",
    "        for i in xrange(index):\n",
    "            _,node = node\n",
    "        return node\n",
    "    \n",
    "    def _search(self, item):\n",
    "        node= self.head\n",
    "        index = 0\n",
    "        while node is not None:\n",
    "            if node[0] == item:\n",
    "                return node,index\n",
    "            _,node = node\n",
    "            index += 1\n",
    "        return None,None\n",
    "    \n",
    "    def search_index(self, item):\n",
    "        node,index = self._search(item)\n",
    "        \n",
    "    def search_node(self, item):\n",
    "        node,index = self._search(item)\n",
    "    \n",
    "    def remove(self, index):\n",
    "        if index == 0:\n",
    "            _, self.head = self.head\n",
    "        else:\n",
    "            parent_node = self.get(index-1)\n",
    "            parent_node[1] = parent_node[1][1]\n",
    "            \n",
    "    def append(self,item):\n",
    "        if self.head == None:\n",
    "            self.push(item)\n",
    "        else:\n",
    "            node = self.head\n",
    "            while node[1] is not None:\n",
    "                _,node = node\n",
    "            node[1] = [item,None]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        node = self.head\n",
    "        items = []\n",
    "        while node is not None:\n",
    "            item,node = node\n",
    "            items.append(str(item))\n",
    "        return ' -> '.join(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = LinkedList()\n",
    "a.append(1)\n",
    "a.append(2)\n",
    "a.append(3)\n",
    "a.get(0)\n",
    "a.insert(5,2)\n",
    "a.remove(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Linked List Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_list():\n",
    "    test_list = LinkedList()\n",
    "    test_list.append(4)\n",
    "    test_list.append(3)\n",
    "    test_list.append(2)\n",
    "    test_list.append(1)\n",
    "    test_list.append(0)\n",
    "    return test_list\n",
    "\n",
    "def test_list_with_big_event():\n",
    "    test_list = create_list()\n",
    "    for query in big_event_queries:\n",
    "        test_list.search_node(query)\n",
    "        \n",
    "def test_list_with_viral():\n",
    "    test_list = create_list()\n",
    "    for query in viral_queries:\n",
    "        test_list.search_node(query)\n",
    "        \n",
    "def test_list_with_constant():\n",
    "    test_list = create_list()\n",
    "    for query in constant_queries:\n",
    "        test_list.search_node(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to create the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field the \"Big Event\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_list_with_big_event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Viral Video\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_list_with_viral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Lopsided but constant distribution\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_list_with_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to Front\n",
    "This technique moves the element which is accessed to the head of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoveToFrontList(LinkedList):\n",
    "    def move_to_front(self,item):\n",
    "        node = self.head\n",
    "        if node[0] == item:\n",
    "            return node[0]\n",
    "        while node is not None:\n",
    "            if node[0] == item:\n",
    "                parent[1] = node[1]\n",
    "                self.push(node[0])\n",
    "                return node[0]\n",
    "            parent = node\n",
    "            node = node[1]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = MoveToFrontList()\n",
    "a.append(1)\n",
    "a.append(2)\n",
    "a.append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.move_to_front(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.move_to_front(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.move_to_front(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mtf_list_5 = MoveToFrontList()\n",
    "test_mtf_list_5.append(4)\n",
    "test_mtf_list_5.append(3)\n",
    "test_mtf_list_5.append(2)\n",
    "test_mtf_list_5.append(1)\n",
    "test_mtf_list_5.append(0)\n",
    "test_mtf_list_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move-to-Front Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_list():\n",
    "    test_mtf_list = MoveToFrontList()\n",
    "    test_mtf_list.append(4)\n",
    "    test_mtf_list.append(3)\n",
    "    test_mtf_list.append(2)\n",
    "    test_mtf_list.append(1)\n",
    "    test_mtf_list.append(0)\n",
    "    return test_mtf_list\n",
    "\n",
    "def test_move_to_front_with_big_event():\n",
    "    test_mtf_list = create_list()\n",
    "    for query in big_event_queries:\n",
    "        test_mtf_list.move_to_front(query)\n",
    "        \n",
    "def test_move_to_front_with_viral():\n",
    "    test_mtf_list = create_list()\n",
    "    for query in viral_queries:\n",
    "        test_mtf_list.move_to_front(query)\n",
    "        \n",
    "def test_move_to_front_with_constant():\n",
    "    test_mtf_list = create_list()\n",
    "    for query in constant_queries:\n",
    "        test_mtf_list.move_to_front(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to create the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field the \"Big Event\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_move_to_front_with_big_event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Viral Video\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_move_to_front_with_viral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Lopsided but constant distribution\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_move_to_front_with_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Method\n",
    "In this technique, the number of times each node was searched for is counted i.e. every node keeps a separate counter variable which is incremented every time it is called. The nodes are then rearranged according to decreasing count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CountList(LinkedList):\n",
    "        \n",
    "    def search(self, item):\n",
    "        node= self.head\n",
    "        index = 0\n",
    "        while node is not None:\n",
    "            if node[0][0] == item:\n",
    "                node[0][1] += 1\n",
    "                self.remove(index)\n",
    "                self.add(node[0])\n",
    "                return \n",
    "            _,node = node\n",
    "            index += 1\n",
    "        \n",
    "    def add(self, new_node):\n",
    "        node = self.head\n",
    "        if node is None or new_node[1] > node[0][1]:\n",
    "            self.head = [new_node,node]\n",
    "            return\n",
    "        while node[1] is not None:\n",
    "            parent = node\n",
    "            _,node = node   \n",
    "            if new_node[1] > node[0][1]:\n",
    "                parent[1] = [new_node,parent[1]]\n",
    "                #print 'Adding {} after {}'.format(str(new_node),str(parent[0]))\n",
    "                return\n",
    "        #print 'Adding {} at end'.format(str(new_node))\n",
    "        node[1] = [new_node,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = CountList()\n",
    "a.add([1,0])\n",
    "a.add([2,0])\n",
    "a.add([3,0])\n",
    "print 'Start:         ',a\n",
    "a.search(3)\n",
    "print 'Search 3:      ',a\n",
    "a.search(3)\n",
    "print 'Search 3 again:',a\n",
    "a.search(2)\n",
    "print 'Search 2:      ',a\n",
    "a.search(2)\n",
    "print 'Search 2 again:',a\n",
    "a.search(2)\n",
    "print 'Search 2 again:',a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Method Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_list():\n",
    "    test_count_list = CountList()\n",
    "    test_count_list.add([4,0])\n",
    "    test_count_list.add([3,0])\n",
    "    test_count_list.add([2,0])\n",
    "    test_count_list.add([1,0])\n",
    "    test_count_list.add([0,0])\n",
    "    return test_count_list\n",
    "\n",
    "def test_count_with_big_event():\n",
    "    test_count_list = create_list()\n",
    "    for query in big_event_queries:\n",
    "        test_count_list.search(query)\n",
    "        \n",
    "def test_count_with_viral():\n",
    "    test_count_list = create_list()\n",
    "    for query in viral_queries:\n",
    "        test_count_list.search(query)\n",
    "    \n",
    "def test_count_with_constant():\n",
    "    test_count_list = create_list()\n",
    "    for query in constant_queries:\n",
    "        test_count_list.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to create the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field the \"Big Event\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_count_with_big_event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Viral Video\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_count_with_viral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Lopsided but constant distribution\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_count_with_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Transpose Method\n",
    "This technique involves swapping an accessed node with its predecessor. Therefore, if any node is accessed, it is swapped with the node in front unless it is the head node, thereby increasing its priority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransposeList(LinkedList):\n",
    "    def search(self,item):\n",
    "        node = self.head\n",
    "        if node[0] == item:\n",
    "            return node\n",
    "        while node is not None:\n",
    "            if node[0] == item:\n",
    "                parent[0],node[0] = node[0],parent[0]\n",
    "                return parent\n",
    "            parent = node\n",
    "            _,node = node             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = TransposeList()\n",
    "a.append(1)\n",
    "a.append(2)\n",
    "a.append(3)\n",
    "print 'Start:   ',a\n",
    "a.search(3)\n",
    "print 'Search 3:',a\n",
    "a.search(3)\n",
    "print 'Search 3:',a\n",
    "a.search(1)\n",
    "print 'Search 1:',a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_list():\n",
    "    test_transpose_list = CountList()\n",
    "    test_transpose_list.add([4,0])\n",
    "    test_transpose_list.add([3,0])\n",
    "    test_transpose_list.add([2,0])\n",
    "    test_transpose_list.add([1,0])\n",
    "    test_transpose_list.add([0,0])\n",
    "    return test_transpose_list\n",
    "\n",
    "def test_transpose_with_big_event():\n",
    "    test_transpose_list = create_list()\n",
    "    for query in big_event_queries:\n",
    "        test_transpose_list.search(query)\n",
    "    \n",
    "\n",
    "def test_transpose_with_viral():\n",
    "    test_transpose_list = create_list()\n",
    "    for query in viral_queries:\n",
    "        test_transpose_list.search(query)\n",
    "        \n",
    "\n",
    "def test_transpose_with_constant():\n",
    "    test_transpose_list = create_list()\n",
    "    for query in constant_queries:\n",
    "        test_transpose_list.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to create the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit create_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field the \"Big Event\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_transpose_with_big_event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Viral Video\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_transpose_with_viral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to field \"Lopsided but constant distribution\" queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit test_transpose_with_constant()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
